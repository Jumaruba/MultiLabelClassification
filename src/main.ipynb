{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0345d8cdc06ab01185019adf9372fed24ef1ecb2b7e5448db4f4b99d257db00a5",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus_train = []\n",
    "ps_train = PorterStemmer()\n",
    "for i in range(0,20972):\n",
    "    # get review and remove non alpha chars\n",
    "    article = re.sub('[^a-zA-Z]', ' ', train['ABSTRACT'][i])\n",
    "    # to lower-case and tokenize\n",
    "    article = article.lower().split()\n",
    "    # stemming and stop word removal\n",
    "    article = ' '.join([ps_train.stem(w) for w in article if not w in set(stopwords.words('english'))])\n",
    "    corpus_train.append(article)\n",
    "df = pd.DataFrame({'train':corpus_train})\n",
    "df.to_csv('preprocessed_train.csv')\n",
    "\n",
    "corpus_test = []\n",
    "ps_test = PorterStemmer()\n",
    "for i in range(0,8989):\n",
    "    # get review and remove non alpha chars\n",
    "    article = re.sub('[^a-zA-Z]', ' ', test['ABSTRACT'][i])\n",
    "    # to lower-case and tokenize\n",
    "    article = article.lower().split()\n",
    "    # stemming and stop word removal\n",
    "    article = ' '.join([ps_test.stem(w) for w in article if not w in set(stopwords.words('english'))])\n",
    "    corpus_test.append(article)\n",
    "df = pd.DataFrame({'test':corpus_test})\n",
    "df.to_csv('preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('preprocessed_train.csv')\n",
    "#test_data = pd.read_csv('preprocessed_test.csv')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features = 1500)\n",
    "\n",
    "X_train_data_array = train_data.loc[:,'train']\n",
    "#X_test_data_array = test_data.loc[:,'test']\n",
    "\n",
    "X = vectorizer.fit_transform(X_train_data_array).toarray()\n",
    "#X_test = vectorizer.fit_transform(X_test_data_array).toarray()\n",
    "\n",
    "y = train.iloc[:,-1].values\n",
    "#y_test = test.iloc[:,-1].values\n",
    "\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16777, 1500) (16777,)\n(4195, 1500) (4195,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[3733  412]\n [  28   22]]\nAccuracy:  0.8951132300357568\nPrecision:  0.05069124423963134\nRecall:  0.44\nF1:  0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4143    2]\n [  43    7]]\nAccuracy:  0.9892729439809297\nPrecision:  0.7777777777777778\nRecall:  0.14\nF1:  0.23728813559322035\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4130   15]\n [  29   21]]\nAccuracy:  0.9895113230035757\nPrecision:  0.5833333333333334\nRecall:  0.42\nF1:  0.4883720930232558\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4125   20]\n [  30   20]]\nAccuracy:  0.9880810488676997\nPrecision:  0.5\nRecall:  0.4\nF1:  0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifier = Perceptron()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4120   25]\n [  33   17]]\nAccuracy:  0.9861740166865316\nPrecision:  0.40476190476190477\nRecall:  0.34\nF1:  0.36956521739130443\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4144    1]\n [  49    1]]\nAccuracy:  0.9880810488676997\nPrecision:  0.5\nRecall:  0.02\nF1:  0.038461538461538464\n[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}